---
layout: default
title: Home
navbar_title: Home
---

{% include widgets/profile_card.html %} {% include widgets/debug_repo_name.html
%} {% include widgets/debug_url.html %}
<div class="my-3 bg-white shadow-none rounded-xl">
  <div class="card border-0 shadow-none bg-white">
    <div class="p-5">
      <div class="h2 font-weight-normal">Research</div>
      <p>
        Davidâ€™s work focuses on reducing societal-scale risks from AI, such as
        the risks of human extinction and
        <a href="https://gradual-disempowerment.ai" target="_blank">
          gradual disempowerment</a
        >. He has published dozens of academic papers about AI and has
        co-authored work with Yoshua Bengio, Geoffrey Hinton, and Jan Leike,
        among others.
      </p>
      <p>
        His research spans many areas of AI, and includes seminal work on
        algorithmic manipulation, misgeneralization, robustness, AI governance,
        and learning from human preferences. An underlying theme of David's
        research is understanding how and why AI systems fail, and tracing that
        back to properties of the data and training process. Some notable
        publications include:
      </p>
      <ul>
        <li>
          <a href="https://arxiv.org/abs/2404.09932" target="_blank"
            >Foundational challenges in assuring alignment and safety of large
            language models</a
          >
        </li>
        <li>
          <a href="https://arxiv.org/abs/2303.09387" target="_blank"
            >Characterizing manipulation from AI systems</a
          >
        </li>
        <li>
          <a href="https://arxiv.org/abs/1706.05394" target="_blank"
            >A closer look at memorization in deep networks</a
          >
        </li>
        <li>
          <a href="https://arxiv.org/abs/2310.17688" target="_blank"
            >Managing extreme AI risks amid rapid progress</a
          >
        </li>
      </ul>
    </div>
  </div>
</div>

<div class="my-3 bg-white shadow-none rounded-xl">
  <div class="card border-0 shadow-none bg-white">
    <div class="p-5">
      <div class="h2 font-weight-normal">Media</div>
      <p>
        David is an outspoken advocate for regulation, social action, and
        international cooperation to prevent the development, deployment, and
        use of dangerous AI systems.
      </p>
      <p>
        David has been featured in prominent media outlets, including
        <a href="https://x.com/GMB/status/1664161142791454720"
          >ITV's Good Morning Britain</a
        >,
        <a href="https://www.nature.com/articles/d41586-025-02616-5">Nature</a>,
        <a
          href="https://www.aljazeera.com/video/inside-story/2023/6/1/does-artificial-intelligence-pose-the-risk-of-human-extinction"
          >Al Jazeera's Inside Story</a
        >,
        <a
          href="https://www.newscientist.com/article/2369626-why-do-some-ai-researchers-dismiss-the-potential-risks-to-humanity/"
          >New Scientist</a
        >, and the
        <a
          href="https://apnews.com/article/artificial-intelligence-risk-of-extinction-ai-54ea8aadc60d1503e5a65878219aad43"
          >Associated Press</a
        >. David has also discussed his work and the risks from AI on podcasts,
        including
        <a href="https://www.youtube.com/watch?v=bDMqo7BpNbk">The Inside View</a
        >,
        <a href="https://www.youtube.com/watch?v=Pnr4ghQo288"
          >Toward Data Science</a
        >
        and
        <a href="https://www.youtube.com/watch?v=aoLhBnog0WM">Earthlings 2.0</a
        >.
      </p>
      <p>
        For media inquiries and interview requests, please contact:
        <a href="mailto:press@davidscottkrueger.com"
          >press@davidscottkrueger.com</a
        >
      </p>
    </div>
  </div>
</div>
