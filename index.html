---
layout: default
title: Homepage
navbar_title: Home
---

{% include widgets/profile_card.html %} {% include widgets/debug_repo_name.html
%} {% include widgets/debug_url.html %}
<div class="my-3 bg-white shadow-none rounded-xl">
  <div class="card border-0 shadow-none bg-white">
    <h6 class="p-3 mb-0 border-bottom border-gray">
      <i class="fas fa-book"></i>&emsp;&emsp;Research
    </h6>
    <div class="p-4">
      <p>
        Davidâ€™s work focuses on reducing societal-scale risks from AI, such as
        the risk of human extinction. He has published dozens of academic papers
        about AI and has co-authored work with Yoshua Bengio, Geoffrey Hinton,
        and Jan Leike, among others.
      </p>
      <p>
        His research spans many areas of AI, and includes seminal work on
        algorithmic manipulation, misgeneralization, robustness, AI governance,
        and learning from human preferences. Some notable publications include:
      </p>
      <ul>
        <li>
          <a
            href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5Uz70IoAAAAJ&citation_for_view=5Uz70IoAAAAJ:vV6vV6tmYwMC"
            target="_blank"
            >Foundational challenges in assuring alignment and safety of large
            language models</a
          >
        </li>
        <li>Characterizing manipulation from AI systems</li>
        <li>
          <a
            href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5Uz70IoAAAAJ&citation_for_view=5Uz70IoAAAAJ:ULOm3_A8WrAC"
            target="_blank"
            >A closer look at memorization in deep networks</a
          >
        </li>
        <li>
          <a
            href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=5Uz70IoAAAAJ&citation_for_view=5Uz70IoAAAAJ:2P1L_qKh6hAC"
            target="_blank"
            >Managing extreme AI risks amid rapid progress</a
          >
        </li>
      </ul>
    </div>
  </div>
</div>

<div class="my-3 bg-white shadow-none rounded-xl">
  <div class="card border-0 shadow-none bg-white">
    <h6 class="p-3 mb-0 border-bottom border-gray">
      <i class="fas fa-newspaper"></i>&emsp;&emsp;Media
    </h6>
    <div class="p-4">
      <p>
        David is an outspoken advocate for regulation, social action, and
        international cooperation to prevent the development, deployment, and
        use of dangerous AI systems.
      </p>
      <p>
        His research spans many areas of AI, and includes seminal work on
        algorithmic manipulation, misgeneralization, robustness, AI governance,
        and learning from human preferences. Some notable publications include:
      </p>
      <p>
        David has been featured in prominent media outlets, including
        <a href="https://x.com/GMB/status/1664161142791454720"
          >ITV's Good Morning Britain</a
        >,
        <a href="https://www.nature.com/articles/d41586-025-02616-5">Nature</a>,
        <a
          href="https://www.aljazeera.com/video/inside-story/2023/6/1/does-artificial-intelligence-pose-the-risk-of-human-extinction"
          >Al Jazeera's Inside Story</a
        >,
        <a
          href="https://www.newscientist.com/article/2369626-why-do-some-ai-researchers-dismiss-the-potential-risks-to-humanity/"
          >New Scientist</a
        >, and the
        <a
          href="https://apnews.com/article/artificial-intelligence-risk-of-extinction-ai-54ea8aadc60d1503e5a65878219aad43"
          >Associated Press</a
        >. David has also discussed his work and the risks from AI on podcasts,
        including
        <a href="https://www.youtube.com/watch?v=bDMqo7BpNbk">The Inside View</a
        >,
        <a href="https://www.youtube.com/watch?v=Pnr4ghQo288"
          >Toward Data Science</a
        >
        and
        <a href="https://www.youtube.com/watch?v=aoLhBnog0WM">Earthlings 2.0</a
        >.
      </p>
    </div>
  </div>
</div>
